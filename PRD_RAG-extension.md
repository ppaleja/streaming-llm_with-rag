# **PRD: Retrieval-Augmented StreamingLLM**

## Introduction

This document outlines the requirements for the "Retrieval-Augmented StreamingLLM" project. The project's core objective is to overcome a key limitation in existing StreamingLLMsâ€”their inability to attend to tokens that have been evicted from the attention window (a "memory lapse"). The proposed solution is to integrate StreamingLLM with a Retrieval-Augmented Generation (RAG) framework.

## 2. Problem Statement

Standard StreamingLLMs are efficient for handling infinite-length sequences by evicting old tokens from the attention cache. However, this leads to a critical loss of information. The model cannot access or recall details that were "forgotten" (evicted), limiting its coherence and utility in tasks that require long-term context, such as long-form Q&A, summarization, or continuous dialogue.

## 3. Goals & Objectives

* **P0 (Primary):** Enable a StreamingLLM to intelligently fetch and re-integrate evicted information (past context) back into its current attention window.
* **P1:** Create a model that can produce infinitely coherent text while retaining access to the complete history of the interaction or document.
* **P1:** Enable the model to access and reason over external databases in conjunction with its streaming, long-term memory.
* **P2:** Outperform baseline StreamingLLM on benchmarks requiring long-context understanding.

## Proposed Solution (High-Level)

The project will integrate the StreamingLLM architecture with a Retrieval-Augmented Generation (RAG) framework, such as LlamaIndex. When the model needs information that is no longer in its immediate context window, the RAG framework will be triggered to search the "evicted" history or an external database and provide the relevant information. This retrieved context will then be fed back into the model's current processing window.

## Key Features & Requirements

* **RAG Framework Integration:**
  * Integrate StreamingLLM with a compatible RAG framework.
  * The framework must be capable of indexing and searching both the evicted token history and specified external databases.
* **Intelligent Retrieval Trigger:**
  * The model must develop a mechanism to recognize when its current context is insufficient.
  * It must be able to formulate and dispatch a query to the RAG system to find the missing information.
* **Context Re-integration:**
  * The model must be able to seamlessly incorporate the retrieved information into its current attention window to generate a coherent and accurate continuation.
* **Performance:**
  * The retrieval process should be efficient to minimize latency and maintain the "streaming" nature of the model.

## Evaluation & Success Metrics

* **Evaluation Strategy 1: Long Document Q&A
  * **Description:** Test the model on question-answering tasks where the questions require synthesizing information from disparate parts of a very long document (i.e., information that would have been evicted).
  * **Success Metric:** % of questions answered correctly compared to a baseline StreamingLLM and a non-streaming RAG model.
* **Evaluation Strategy 2: Long-Form Summarization**
  * **Description:** Task the model with summarizing an extremely long text.
  * **Success Metric:** ROUGE/BERTScore and human evaluation of summary coherence and completeness, ensuring key points from the *entire* text are included.

## Potential Applications

* **Persistent Daily Assistant:** An assistant that can maintain a continuous, coherent conversation over days or weeks, remembering past interactions and user preferences (e.g., assisting with email management, analysis, weather updates, etc., as noted in the "Persistent Daily Assistant" idea).
* **Long-Form Content Analysis:** Analyzing and querying multi-hour-long meeting transcripts, entire codebases, or complete books.
